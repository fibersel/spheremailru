{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 30 апреля 2018, 06:00   \n",
    "**Штраф за опоздание:** -2 балла после 06:00 30 апреля, -4 балла после 06:00 7 мая, -6 баллов после 06:00 14 мая, -8 баллов после 06:00 21 мая\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "    FEATURE_THRESHOLD = 1e-7\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        min_samples_split=2,\n",
    "        max_depth=None,\n",
    "        sufficient_share=1.0,\n",
    "        criterion='gini',\n",
    "        max_features=None\n",
    "    ):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return ((1 - np.sum(\n",
    "            (np.bincount(l_c) / l_c.shape[0]) ** 2\n",
    "        )) * l_c.shape[0] + (1 - np.sum(\n",
    "            (np.bincount(r_c) / r_c.shape[0]) ** 2)\n",
    "                            ) * r_c.shape[0]) / (l_c.shape[0] + r_c.shape[0])\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return  # Ваш код в 1 строчку\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return  # Ваш код в 1 строчку\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[: int(np.sqrt(feature_ids.shape[0]))]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[: int(np.log(feature_ids.shape[0]) / np.log(2))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        feature_ids = self.get_feature_ids(x.shape[1])\n",
    "        min_gain = 2\n",
    "        for idx in feature_ids:\n",
    "            col = x[:, idx]\n",
    "            col, y_sort = self.__sort_samples(col, y)\n",
    "            for ind in np.where(y_sort[:-1] != y_sort[1:])[0] + 1:\n",
    "                l_s, r_s = col[:ind], col[ind:]\n",
    "                l_c, r_c = y_sort[:ind], y_sort[ind:]\n",
    "                gain = self.G_function(l_c, l_s, r_c, r_s)\n",
    "                if gain == 0:\n",
    "                    return idx, col[ind - 1], ind\n",
    "                if gain < min_gain:\n",
    "                    res_idx = idx\n",
    "                    res_thr = col[ind - 1]\n",
    "                    res_ind = ind\n",
    "                    min_gain = gain\n",
    "        return res_idx, res_thr, res_ind\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        if depth == self.max_depth or self.min_samples_split >= x.shape[0] or len(np.unique(y)) == 1:\n",
    "            self.tree[node_id] = [self.__class__.LEAF_TYPE,\n",
    "                                  np.argmax(np.bincount(y))]\n",
    "            return\n",
    "        feature_id, threshold, split_ind = self.__find_threshold(x, y)\n",
    "        self.tree[node_id] = [self.__class__.NON_LEAF_TYPE,\n",
    "                              feature_id, threshold]\n",
    "        x_tmp = x[x[:, feature_id].argsort()]\n",
    "        y_tmp = y[x[:, feature_id].argsort()]\n",
    "        X_left, X_right, y_left, y_right = x_tmp[split_ind:], x_tmp[:split_ind], y_tmp[split_ind:], y_tmp[:split_ind]\n",
    "#        print(y_left, y_right, threshold, x[:, feature_id])\n",
    "        self.__fit_node(X_left, y_left, 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(X_right, y_right, 2 * node_id + 2, depth + 1)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_features='sqrt')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.86 ms, sys: 38 µs, total: 3.9 ms\n",
      "Wall time: 4.43 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 ms, sys: 8.02 ms, total: 60.8 ms\n",
      "Wall time: 58.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890993265993266"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94747474747474747"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = pd.read_csv('speed-dating-experiment/Speed Dating Data.csv', sep=',', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data_processed = Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in Data.columns: \n",
    "    if Data[feat].dtype == 'object':\n",
    "        Data_processed[feat] = Data[[feat]].fillna('0').apply(preprocessing.LabelEncoder().fit_transform)[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_processed.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(Data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.2 ms, sys: 16 ms, total: 69.3 ms\n",
      "Wall time: 68.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(train.drop(target, axis=1), train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(clf.predict(np.array(test.drop(target, axis=1))), np.array(test[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cycle: 0\n",
      "cycle: 1\n",
      "cycle: 2\n",
      "cycle: 3\n",
      "cycle: 4\n",
      "cycle: 5\n",
      "cycle: 6\n",
      "cycle: 7\n",
      "cycle: 8\n",
      "cycle: 9\n",
      "cycle: 10\n",
      "cycle: 11\n",
      "cycle: 12\n",
      "cycle: 13\n",
      "cycle: 14\n",
      "cycle: 15\n",
      "cycle: 16\n",
      "cycle: 17\n",
      "cycle: 18\n",
      "cycle: 19\n",
      "cycle: 20\n",
      "cycle: 21\n",
      "cycle: 22\n",
      "cycle: 23\n",
      "cycle: 24\n",
      "cycle: 25\n",
      "cycle: 26\n",
      "cycle: 27\n",
      "cycle: 28\n",
      "cycle: 29\n",
      "cycle: 30\n",
      "cycle: 31\n",
      "cycle: 32\n",
      "cycle: 33\n",
      "cycle: 34\n",
      "cycle: 35\n",
      "cycle: 36\n",
      "cycle: 37\n",
      "cycle: 38\n",
      "cycle: 39\n",
      "cycle: 40\n",
      "cycle: 41\n",
      "cycle: 42\n",
      "cycle: 43\n",
      "cycle: 44\n",
      "cycle: 45\n",
      "cycle: 46\n",
      "cycle: 47\n",
      "cycle: 48\n",
      "cycle: 49\n",
      "cycle: 50\n",
      "cycle: 51\n",
      "cycle: 52\n",
      "cycle: 53\n",
      "cycle: 54\n",
      "cycle: 55\n",
      "cycle: 56\n",
      "cycle: 57\n",
      "cycle: 58\n",
      "cycle: 59\n",
      "cycle: 60\n",
      "cycle: 61\n",
      "cycle: 62\n",
      "cycle: 63\n",
      "cycle: 64\n",
      "cycle: 65\n",
      "cycle: 66\n",
      "cycle: 67\n",
      "cycle: 68\n",
      "cycle: 69\n",
      "cycle: 70\n",
      "cycle: 71\n",
      "cycle: 72\n",
      "cycle: 73\n",
      "cycle: 74\n",
      "cycle: 75\n",
      "cycle: 76\n",
      "cycle: 77\n",
      "cycle: 78\n",
      "cycle: 79\n",
      "cycle: 80\n",
      "cycle: 81\n",
      "cycle: 82\n",
      "cycle: 83\n",
      "cycle: 84\n",
      "cycle: 85\n",
      "cycle: 86\n",
      "cycle: 87\n",
      "cycle: 88\n",
      "cycle: 89\n",
      "cycle: 90\n",
      "cycle: 91\n",
      "cycle: 92\n",
      "cycle: 93\n",
      "cycle: 94\n",
      "cycle: 95\n",
      "cycle: 96\n",
      "cycle: 97\n",
      "cycle: 98\n",
      "cycle: 99\n",
      "cycle: 100\n",
      "cycle: 101\n",
      "cycle: 102\n",
      "cycle: 103\n",
      "cycle: 104\n",
      "cycle: 105\n",
      "cycle: 106\n",
      "cycle: 107\n",
      "cycle: 108\n",
      "cycle: 109\n",
      "cycle: 110\n",
      "cycle: 111\n",
      "cycle: 112\n",
      "cycle: 113\n",
      "cycle: 114\n",
      "cycle: 115\n",
      "cycle: 116\n",
      "cycle: 117\n",
      "cycle: 118\n",
      "cycle: 119\n",
      "cycle: 120\n",
      "cycle: 121\n",
      "cycle: 122\n",
      "cycle: 123\n",
      "cycle: 124\n",
      "cycle: 125\n",
      "cycle: 126\n",
      "cycle: 127\n",
      "cycle: 128\n",
      "cycle: 129\n",
      "cycle: 130\n",
      "cycle: 131\n",
      "cycle: 132\n",
      "cycle: 133\n",
      "cycle: 134\n",
      "cycle: 135\n",
      "cycle: 136\n",
      "cycle: 137\n",
      "cycle: 138\n",
      "cycle: 139\n",
      "cycle: 140\n",
      "cycle: 141\n",
      "cycle: 142\n",
      "cycle: 143\n",
      "cycle: 144\n",
      "cycle: 145\n",
      "cycle: 146\n",
      "cycle: 147\n",
      "cycle: 148\n",
      "cycle: 149\n",
      "cycle: 150\n",
      "cycle: 151\n",
      "cycle: 152\n",
      "cycle: 153\n",
      "cycle: 154\n",
      "cycle: 155\n",
      "cycle: 156\n",
      "cycle: 157\n",
      "cycle: 158\n",
      "cycle: 159\n",
      "cycle: 160\n",
      "cycle: 161\n",
      "cycle: 162\n",
      "cycle: 163\n",
      "cycle: 164\n",
      "cycle: 165\n",
      "cycle: 166\n",
      "cycle: 167\n",
      "cycle: 168\n",
      "cycle: 169\n",
      "cycle: 170\n",
      "cycle: 171\n",
      "cycle: 172\n",
      "cycle: 173\n",
      "cycle: 174\n",
      "cycle: 175\n",
      "cycle: 176\n",
      "cycle: 177\n",
      "cycle: 178\n",
      "cycle: 179\n",
      "cycle: 180\n",
      "cycle: 181\n",
      "cycle: 182\n",
      "cycle: 183\n",
      "cycle: 184\n",
      "cycle: 185\n",
      "cycle: 186\n",
      "cycle: 187\n",
      "cycle: 188\n",
      "cycle: 189\n",
      "cycle: 190\n",
      "cycle: 191\n",
      "cycle: 192\n",
      "cycle: 193\n",
      "1\n",
      "cycle: 0\n",
      "cycle: 1\n",
      "cycle: 2\n",
      "cycle: 3\n",
      "cycle: 4\n",
      "cycle: 5\n",
      "cycle: 6\n",
      "cycle: 7\n",
      "cycle: 8\n",
      "cycle: 9\n",
      "cycle: 10\n",
      "cycle: 11\n",
      "cycle: 12\n",
      "cycle: 13\n",
      "cycle: 14\n",
      "cycle: 15\n",
      "cycle: 16\n",
      "cycle: 17\n",
      "cycle: 18\n",
      "cycle: 19\n",
      "cycle: 20\n",
      "cycle: 21\n",
      "cycle: 22\n",
      "cycle: 23\n",
      "cycle: 24\n",
      "cycle: 25\n",
      "cycle: 26\n",
      "cycle: 27\n",
      "cycle: 28\n",
      "cycle: 29\n",
      "cycle: 30\n",
      "cycle: 31\n",
      "cycle: 32\n",
      "cycle: 33\n",
      "cycle: 34\n",
      "cycle: 35\n",
      "cycle: 36\n",
      "cycle: 37\n",
      "cycle: 38\n",
      "cycle: 39\n",
      "cycle: 40\n",
      "cycle: 41\n",
      "cycle: 42\n",
      "cycle: 43\n",
      "cycle: 44\n",
      "cycle: 45\n",
      "cycle: 46\n",
      "cycle: 47\n",
      "cycle: 48\n",
      "cycle: 49\n",
      "cycle: 50\n",
      "cycle: 51\n",
      "cycle: 52\n",
      "cycle: 53\n",
      "cycle: 54\n",
      "cycle: 55\n",
      "cycle: 56\n",
      "cycle: 57\n",
      "cycle: 58\n",
      "cycle: 59\n",
      "cycle: 60\n",
      "cycle: 61\n",
      "cycle: 62\n",
      "cycle: 63\n",
      "cycle: 64\n",
      "cycle: 65\n",
      "cycle: 66\n",
      "cycle: 67\n",
      "CPU times: user 17.5 s, sys: 47.9 ms, total: 17.6 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(np.array(train.drop(target, axis=1)), np.array(train[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(my_clf.predict(np.array(test.drop(target, axis=1))), np.array(test[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 22, 0.0], 1: [0, 96, 0.0], 2: [1, 0], 3: [1, 1], 4: [1, 0]}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nd_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(np.array([1, 2, 3]), np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(6).reshape(2, -1)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "    FEATURE_THRESHOLD = 1e-7\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        min_samples_split=2,\n",
    "        max_depth=None,\n",
    "        sufficient_share=1.0,\n",
    "        criterion='gini',\n",
    "        max_features=None\n",
    "    ):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return ((1 - np.sum(\n",
    "            (np.bincount(l_c) / l_c.shape[0]) ** 2\n",
    "        )) * l_c.shape[0] + (1 - np.sum(\n",
    "            (np.bincount(r_c) / r_c.shape[0]) ** 2)\n",
    "                            ) * r_c.shape[0]) / (l_c.shape[0] + r_c.shape[0])\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return  # Ваш код в 1 строчку\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return  # Ваш код в 1 строчку\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[: int(np.sqrt(feature_ids.shape[0]))]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = np.arange(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[: int(np.log(feature_ids.shape[0]) / np.log(2))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y, node_id):\n",
    "        print(node_id)\n",
    "        feats = self._feats[max(0, (node_id - 1) // 2)]\n",
    "        np.random.shuffle(feats)\n",
    "        #feature_ids = self.get_feature_ids()\n",
    "        constf = - np.ones(x.shape[1])\n",
    "        ctr = 0\n",
    "        min_gain = 2\n",
    "        cycle = 0\n",
    "        for idx in feats:\n",
    "            print(f\"cycle: {cycle}\")\n",
    "            cycle += 1\n",
    "            col = x[:, idx]\n",
    "            col, y_sort = self.__sort_samples(col, y)\n",
    "            if col[-1] <= col[0] + self.__class__.FEATURE_THRESHOLD:\n",
    "                constf[ctr] = idx\n",
    "                ctr += 1\n",
    "                continue\n",
    "            for ind in np.where(y_sort[:-1] != y_sort[1:])[0] + 1:\n",
    "                l_s, r_s = col[:ind], col[ind:]\n",
    "                l_c, r_c = y_sort[:ind], y_sort[ind:]\n",
    "                gain = self.G_function(l_c, l_s, r_c, r_s)\n",
    "                if gain == 0:\n",
    "                    self._feats[node_id] = feats[~np.isin(feats, constf)]\n",
    "                    return idx, col[ind - 1], ind\n",
    "                if gain < min_gain:\n",
    "                    res_idx = idx\n",
    "                    res_thr = col[ind - 1]\n",
    "                    res_ind = ind\n",
    "                    min_gain = gain\n",
    "        self._feats[node_id] = feats[~np.isin(feats, constf)]\n",
    "        return res_idx, res_thr, res_ind\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        if depth == self.max_depth or self.min_samples_split >= x.shape[0] or len(np.unique(y)) == 1:\n",
    "            self.tree[node_id] = [self.__class__.LEAF_TYPE,\n",
    "                                  np.argmax(np.bincount(y))]\n",
    "            return\n",
    "        feature_id, threshold, split_ind = self.__find_threshold(x, y, node_id)\n",
    "        self.tree[node_id] = [self.__class__.NON_LEAF_TYPE,\n",
    "                              feature_id, threshold]\n",
    "        x_tmp = x[x[:, feature_id].argsort()]\n",
    "        y_tmp = y[x[:, feature_id].argsort()]\n",
    "        X_left, X_right, y_left, y_right = x_tmp[split_ind:], x_tmp[:split_ind], y_tmp[split_ind:], y_tmp[:split_ind]\n",
    "#        print(y_left, y_right, threshold, x[:, feature_id])\n",
    "        self.__fit_node(X_left, y_left, 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(X_right, y_right, 2 * node_id + 2, depth + 1)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self._feats = {0: np.arange(x.shape[1])}\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# тут должен быть код типа %time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# тут должен быть код типа %time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
